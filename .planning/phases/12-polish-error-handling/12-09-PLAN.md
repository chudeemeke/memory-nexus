---
phase: 12-polish-error-handling
plan: 09
type: execute
wave: 4
depends_on: ["12-04"]
files_modified:
  - tests/integration/large-file.test.ts
  - tests/integration/interrupted-sync.test.ts
  - tests/integration/concurrent-commands.test.ts
  - tests/integration/index.ts
autonomous: true

must_haves:
  truths:
    - "Parser handles 10K+ line files without memory exhaustion"
    - "Interrupted sync can be resumed from checkpoint"
    - "Concurrent CLI commands do not deadlock"
  artifacts:
    - path: "tests/integration/large-file.test.ts"
      provides: "10K+ line file parsing tests"
    - path: "tests/integration/interrupted-sync.test.ts"
      provides: "Sync recovery tests"
    - path: "tests/integration/concurrent-commands.test.ts"
      provides: "Concurrent access tests"
  key_links:
    - from: "tests/integration/large-file.test.ts"
      to: "src/infrastructure/parsers/jsonl-parser.ts"
      via: "streaming parser verification"
      pattern: "parseJsonl"
---

<objective>
Create integration tests for edge cases: large files, interrupted sync, and concurrent access.

Purpose: Validate that the system handles production-scale workloads and failure scenarios correctly. These tests verify requirements QUAL-03, QUAL-04, and QUAL-05.

Output: Integration test suite covering large files, sync recovery, and concurrency.
</objective>

<execution_context>
@C:\Users\Destiny\.claude/get-stuff-done/workflows/execute-plan.md
@C:\Users\Destiny\.claude/get-stuff-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-polish-error-handling/12-CONTEXT.md
@src/infrastructure/parsers/jsonl-parser.ts
@src/application/services/sync-service.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create large file integration tests</name>
  <files>
    tests/integration/large-file.test.ts
  </files>
  <action>
    Create integration tests for 10K+ line file parsing:

    1. Create tests/integration/large-file.test.ts:
       - Helper: generateLargeJsonl(lineCount: number, filePath: string)
         - Generate valid JSONL with lineCount events
         - Mix of user, assistant, tool_use events
         - Realistic content (not just empty objects)

       - Test: "parses 10,000 line file without memory spike"
         - Generate 10,000 line file
         - Record memory before: process.memoryUsage().heapUsed
         - Parse file using streaming parser
         - Record memory after
         - Assert memory increase < 50MB (per STATE.md learning)
         - Assert all events parsed correctly

       - Test: "parses 50,000 line file without memory spike"
         - Same pattern with larger file
         - Memory increase should still be bounded

       - Test: "maintains performance with large files"
         - Parse 10,000 line file
         - Assert completion < 5 seconds
         - Track time per line for regression detection

       - Test: "handles malformed lines in large file gracefully"
         - Generate file with some invalid JSON scattered throughout
         - Parser should skip invalid lines and continue
         - Count valid vs skipped events

    2. Use temp directories for test files
       - Clean up after tests
       - Don't pollute working directory
  </action>
  <verify>
    Run: bun test tests/integration/large-file.test.ts
    All tests pass.
    Verify memory usage stays bounded.
  </verify>
  <done>
    10K+ line files parsed without memory exhaustion.
    50K line files also handled (stress test).
    Performance acceptable (< 5s for 10K lines).
    Malformed lines handled gracefully.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create sync recovery and concurrency tests</name>
  <files>
    tests/integration/interrupted-sync.test.ts
    tests/integration/concurrent-commands.test.ts
    tests/integration/index.ts
  </files>
  <action>
    Create integration tests for sync recovery and concurrency:

    1. Create tests/integration/interrupted-sync.test.ts:
       - Test: "resumes sync from checkpoint after interruption"
         - Set up test sessions
         - Start sync with checkpoint enabled
         - Simulate interruption after N sessions (set shouldAbort)
         - Verify checkpoint saved with correct progress
         - Start new sync
         - Verify only remaining sessions processed
         - Verify checkpoint cleared after completion

       - Test: "handles corrupted checkpoint gracefully"
         - Write invalid JSON to checkpoint file
         - Start sync
         - Should log warning and start fresh (not crash)

       - Test: "handles missing sessions from checkpoint"
         - Save checkpoint referencing non-existent sessions
         - Start sync
         - Should proceed normally (skip missing)

    2. Create tests/integration/concurrent-commands.test.ts:
       - Test: "search during sync does not deadlock"
         - Start sync in background (use async)
         - Immediately run search query
         - Both should complete (not block forever)
         - Use timeout to detect deadlock

       - Test: "multiple searches in parallel work correctly"
         - Run 5 search queries in parallel
         - All should return results
         - No deadlock or corruption

       - Test: "stats during sync returns consistent data"
         - Start sync
         - Run stats command
         - Results should be consistent (WAL isolation)

    3. Create tests/integration/index.ts:
       - Export test utilities for other integration tests
       - Helper: setupTestDatabase()
       - Helper: generateTestSessions()
       - Helper: cleanupTestData()
  </action>
  <verify>
    Run: bun test tests/integration/interrupted-sync.test.ts
    Run: bun test tests/integration/concurrent-commands.test.ts
    All tests pass without deadlocks or timeouts.
  </verify>
  <done>
    Interrupted sync recovers correctly from checkpoint.
    Corrupted checkpoint handled gracefully.
    Concurrent commands don't deadlock.
    WAL mode provides proper isolation.
  </done>
</task>

</tasks>

<verification>
1. Run: bun test tests/integration - All integration tests pass
2. Verify no timeouts (would indicate deadlock)
3. Verify memory stays bounded for large files
4. Verify checkpoint recovery works correctly
</verification>

<success_criteria>
1. 10K+ line files parsed with < 50MB memory increase
2. Performance: 10K lines in < 5 seconds
3. Interrupted sync resumes correctly from checkpoint
4. Corrupted/invalid checkpoints don't crash system
5. Concurrent sync + search don't deadlock
6. Multiple parallel searches work correctly
</success_criteria>

<output>
After completion, create `.planning/phases/12-polish-error-handling/12-09-SUMMARY.md`
</output>
